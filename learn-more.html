<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>What EmbeddingAdapters Can Do ‚Äî Features & Capabilities</title>
<meta name="description" content="Cross-model embedding translation, confidence scoring, CLI tools, vector database compatibility, provider migration, A/B testing, GPU/CPU support, custom adapter training, and fully local private inference.">
<meta name="keywords" content="embedding translation features, cross-model retrieval, embedding confidence scoring, vector database migration, embedding model A/B testing, custom embedding adapters, local embedding inference, embedding-adapters capabilities, openai embedding alternative, minilm to openai translation">
<meta name="robots" content="index, follow">
<link rel="canonical" href="https://embeddingadapters.com/learn-more.html">
<meta property="og:type" content="website">
<meta property="og:url" content="https://embeddingadapters.com/learn-more.html">
<meta property="og:title" content="What EmbeddingAdapters Can Do ‚Äî All Features">
<meta property="og:description" content="Cross-model embedding translation, confidence scoring, CLI tools, custom training, and more. Everything EmbeddingAdapters can do for your embedding pipeline.">
<meta property="og:site_name" content="EmbeddingAdapters">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="EmbeddingAdapters Features & Capabilities">
<meta name="twitter:description" content="Cross-model embedding translation, confidence scoring, CLI tools, custom training, and more.">

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebPage",
  "name": "EmbeddingAdapters Features & Capabilities",
  "description": "Everything EmbeddingAdapters can do: cross-model embedding translation, confidence scoring, CLI, vector DB support, custom training, and local inference.",
  "url": "https://embeddingadapters.com/learn-more.html",
  "isPartOf": {
    "@type": "WebSite",
    "name": "EmbeddingAdapters",
    "url": "https://embeddingadapters.com"
  }
}
</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@400;500;600;700&family=Source+Serif+4:wght@700;800&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
<style>
:root {
  --accent: #2563eb;
  --accent-light: #3b82f6;
  --text-primary: #0f172a;
  --text-secondary: #475569;
  --text-muted: #94a3b8;
  --bg: #f8fafc;
  --bg-card: #ffffff;
  --border: #e2e8f0;
  --font-body: 'DM Sans', sans-serif;
  --font-display: 'Source Serif 4', Georgia, serif;
  --font-mono: 'JetBrains Mono', monospace;
  --radius: 12px;
  --shadow-sm: 0 1px 4px rgba(15,23,41,0.06);
}

* { margin: 0; padding: 0; box-sizing: border-box; }

body {
  font-family: var(--font-body);
  background: var(--bg);
  color: var(--text-primary);
  line-height: 1.7;
  -webkit-font-smoothing: antialiased;
}

/* Nav */
nav {
  position: sticky;
  top: 0;
  z-index: 100;
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 16px 32px;
  background: rgba(248,250,252,0.9);
  backdrop-filter: blur(12px);
  border-bottom: 1px solid rgba(226,232,240,0.5);
}

.nav-logo {
  display: flex;
  align-items: center;
  gap: 10px;
  text-decoration: none;
  color: var(--text-primary);
}

.nav-logo svg { width: 28px; height: 28px; }
.nav-logo span { font-weight: 600; font-size: 17px; letter-spacing: -0.02em; }

.nav-back {
  font-size: 14px;
  font-weight: 500;
  color: var(--accent);
  text-decoration: none;
  transition: color 0.2s;
}

.nav-back:hover { color: var(--accent-light); }

/* Hero */
.page-hero {
  max-width: 760px;
  margin: 0 auto;
  padding: 80px 24px 48px;
  text-align: center;
}

.page-hero h1 {
  font-family: var(--font-display);
  font-size: clamp(32px, 5vw, 48px);
  font-weight: 800;
  line-height: 1.15;
  letter-spacing: -0.03em;
  margin-bottom: 16px;
}

.page-hero p {
  font-size: 18px;
  color: var(--text-secondary);
  max-width: 560px;
  margin: 0 auto;
  line-height: 1.65;
}

/* Content */
.content {
  max-width: 760px;
  margin: 0 auto;
  padding: 0 24px 80px;
}

.capability {
  margin-bottom: 48px;
  padding: 32px;
  background: var(--bg-card);
  border: 1px solid var(--border);
  border-radius: var(--radius);
  transition: box-shadow 0.2s;
}

.capability:hover {
  box-shadow: var(--shadow-sm);
}

.cap-header {
  display: flex;
  align-items: flex-start;
  gap: 16px;
  margin-bottom: 14px;
}

.cap-icon {
  font-size: 28px;
  line-height: 1;
  flex-shrink: 0;
  width: 48px;
  height: 48px;
  display: flex;
  align-items: center;
  justify-content: center;
  background: rgba(37,99,235,0.06);
  border-radius: 10px;
}

.cap-header h3 {
  font-family: var(--font-display);
  font-size: 22px;
  font-weight: 700;
  letter-spacing: -0.01em;
  line-height: 1.3;
  padding-top: 4px;
}

.capability p {
  color: var(--text-secondary);
  font-size: 15px;
  line-height: 1.7;
  margin-bottom: 12px;
}

.capability p:last-child { margin-bottom: 0; }

.cap-code {
  background: #0f172a;
  color: #e2e8f0;
  font-family: var(--font-mono);
  font-size: 13px;
  padding: 16px 20px;
  border-radius: 8px;
  overflow-x: auto;
  margin-top: 16px;
  line-height: 1.6;
}

.cap-code .kw { color: #93c5fd; }
.cap-code .str { color: #a5d6ff; }
.cap-code .comment { color: rgba(255,255,255,0.3); font-style: italic; }

/* CTA */
.page-cta {
  text-align: center;
  padding: 0 24px 80px;
}

.page-cta a {
  display: inline-flex;
  align-items: center;
  gap: 8px;
  background: var(--accent);
  color: #fff;
  padding: 14px 32px;
  border-radius: 10px;
  font-size: 15px;
  font-weight: 600;
  text-decoration: none;
  transition: all 0.2s;
  box-shadow: 0 2px 12px rgba(37,99,235,0.25);
}

.page-cta a:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 24px rgba(37,99,235,0.3);
}

@media (max-width: 600px) {
  .page-hero { padding: 56px 20px 32px; }
  .page-hero h1 { font-size: 28px; }
  .page-hero p { font-size: 15px; }
  .capability { padding: 24px 20px; }
  .cap-header h3 { font-size: 18px; }
  nav { padding: 14px 16px; }
}
</style>
</head>
<body>

<nav>
  <a href="index.html" class="nav-logo">
    <svg viewBox="0 0 28 28" fill="none">
      <rect width="28" height="28" rx="7" fill="#2563eb"/>
      <path d="M7 14h5l3-6 3 12 3-6h5" stroke="#fff" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
    </svg>
    <span>EmbeddingAdapters</span>
  </a>
  <a href="index.html" class="nav-back">‚Üê Back to home</a>
</nav>

<div class="page-hero">
  <h1>Everything EmbeddingAdapters can do</h1>
  <p>One library for translating, comparing, and routing embeddings across any model or provider ‚Äî without re-indexing your vector store.</p>
</div>

<div class="content">

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üîÑ</div>
      <h3>Cross-model embedding translation</h3>
    </div>
    <p>Translate embeddings from any source model into any target model's space. Query a Pinecone index built with OpenAI embeddings using a local MiniLM model ‚Äî or vice versa. Adapters learn the mapping between embedding spaces so you never need to re-embed your data.</p>
    <div class="cap-code">
<span class="kw">from</span> embedding_adapters <span class="kw">import</span> adapt

<span class="comment"># Translate MiniLM embeddings ‚Üí OpenAI space</span>
adapted = adapt(
    embedding,
    source=<span class="str">"sentence-transformers/all-MiniLM-L6-v2"</span>,
    target=<span class="str">"openai/text-embedding-3-small"</span>
)</div>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üìä</div>
      <h3>Confidence scoring</h3>
    </div>
    <p>Every translation returns a confidence score that tells you how reliable the adapted embedding is for your specific input. Use this for smart routing ‚Äî fall back to the native model when confidence is low, or use the adapter when it's high to save cost and latency.</p>
    <div class="cap-code">
result = adapt(embedding, source=<span class="str">"bge"</span>, target=<span class="str">"openai"</span>)
<span class="kw">print</span>(result.confidence)  <span class="comment"># 0.94 ‚Äî high confidence</span>
<span class="kw">print</span>(result.embedding)    <span class="comment"># adapted vector</span></div>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">‚ö°</div>
      <h3>CLI for quick experiments</h3>
    </div>
    <p>Test translations instantly from the command line without writing any code. Pipe in text, get back adapted embeddings in JSON format. Great for prototyping and debugging retrieval pipelines.</p>
    <div class="cap-code">
<span class="comment">$ embedding-adapters embed \</span>
<span class="comment">    --source all-MiniLM-L6-v2 \</span>
<span class="comment">    --target openai/text-embedding-3-small \</span>
<span class="comment">    --text "semantic search query"</span></div>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üîå</div>
      <h3>Works with any vector database</h3>
    </div>
    <p>EmbeddingAdapters is database-agnostic. It operates on the embedding vectors themselves, so it works alongside Pinecone, Weaviate, Qdrant, pgvector, Milvus, FAISS, ChromaDB, or any other vector store. No vendor lock-in, no special integrations needed.</p>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üèóÔ∏è</div>
      <h3>Multiple adapter sizes</h3>
    </div>
    <p>Choose the right trade-off for your use case. Small adapters are lightweight and fast for edge deployment. Large adapters deliver maximum translation fidelity for production search systems. The <code>--flavor</code> flag switches between them instantly.</p>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üîÄ</div>
      <h3>Provider migration without downtime</h3>
    </div>
    <p>Switching from one embedding provider to another? Instead of re-embedding millions of documents (which can take days and cost thousands), use an adapter to query your existing index with the new model immediately. Migrate gradually on your own schedule.</p>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üß™</div>
      <h3>A/B testing embedding models</h3>
    </div>
    <p>Compare how different models perform on your specific data without maintaining separate indexes. Translate queries into each model's space, run retrieval, and compare results ‚Äî all against a single vector store.</p>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üèéÔ∏è</div>
      <h3>GPU &amp; CPU support</h3>
    </div>
    <p>Adapters run on CUDA when available for batch processing, and fall back gracefully to CPU. The models are small enough (typically &lt;50MB) for edge deployment, serverless functions, or even in-browser inference.</p>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üéØ</div>
      <h3>Custom adapter training</h3>
    </div>
    <p>Train adapters on your own domain data for higher fidelity translations on specialized corpora. Legal documents, medical records, code repositories ‚Äî custom-trained adapters consistently outperform the general-purpose public models on domain-specific retrieval tasks.</p>
  </div>

  <div class="capability">
    <div class="cap-header">
      <div class="cap-icon">üõ°Ô∏è</div>
      <h3>Fully local &amp; private</h3>
    </div>
    <p>Everything runs on your infrastructure. No data leaves your network, no API calls to external services during inference. Adapters are deterministic ‚Äî the same input always produces the same output, making them safe for regulated environments and reproducible pipelines.</p>
  </div>

</div>

<div class="page-cta">
  <a href="https://github.com/PotentiallyARobot/EmbeddingAdapters#readme">
    Get started with EmbeddingAdapters
    <svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M3 8h10m0 0L9 4m4 4l-4 4" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/></svg>
  </a>
</div>

</body>
</html>
